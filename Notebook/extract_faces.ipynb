{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /content/drive/MyDrive/\n",
    "mkdir -p CS777\n",
    "cd CS777\n",
    "git clone -b feat-diffusion https://github.com/Stanford997/METCS777-GenAIForTheme.git"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c92671fc571a1c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r METCS777-GenAIForTheme/requirements.txt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8121450058ad6c3c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import traceback\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import blazeface\n",
    "from blazeface import BlazeFace, VideoReader, FaceExtractor\n",
    "from isplutils.utils import adapt_bb"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a5a09d9ab1c24b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_args(argv):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--source', type=Path, help='Videos root directory', required=True)\n",
    "    parser.add_argument('--videodf', type=Path, help='Path to read the videos DataFrame', required=True)\n",
    "    parser.add_argument('--facesfolder', type=Path, help='Faces output root directory', required=True)\n",
    "    parser.add_argument('--facesdf', type=Path, help='Path to save the output DataFrame of faces', required=True)\n",
    "    parser.add_argument('--checkpoint', type=Path, help='Path to save the temporary per-video outputs', required=True)\n",
    "\n",
    "    parser.add_argument('--fpv', type=int, default=10, help='Frames per video')\n",
    "    parser.add_argument('--device', type=torch.device,\n",
    "                        default=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
    "                        help='Device to use for face extraction')\n",
    "    parser.add_argument('--collateonly', help='Only perform collation of pre-existing results', action='store_true')\n",
    "    parser.add_argument('--noindex', help='Do not rebuild the index', action='store_false')\n",
    "    parser.add_argument('--batch', type=int, help='Batch size', default=16)\n",
    "    parser.add_argument('--threads', type=int, help='Number of threads', default=8)\n",
    "    parser.add_argument('--offset', type=int, help='Offset to start extraction', default=0)\n",
    "    parser.add_argument('--num', type=int, help='Number of videos to process', default=0)\n",
    "    parser.add_argument('--lazycheck', action='store_true', help='Lazy check of existing video indexes')\n",
    "    parser.add_argument('--deepcheck', action='store_true', help='Try to open every image')\n",
    "\n",
    "    return parser.parse_args(argv)\n",
    "\n",
    "\n",
    "argv = [\n",
    "    '--source', '/Users/caozhen/Deepfake-Detection/Datasets',\n",
    "    '--videodf', '/Users/caozhen/PycharmProjects/BU-assignment/CS599/Project/data/ffpp_videos.pkl',\n",
    "    '--facesfolder', '/Users/caozhen/PycharmProjects/BU-assignment/CS599/Project/Dataset/image',\n",
    "    '--facesdf', '/Users/caozhen/PycharmProjects/BU-assignment/CS599/Project/Dataset/image_df/df.pkl',\n",
    "    '--checkpoint', '/Users/caozhen/PycharmProjects/BU-assignment/CS599/Project/Dataset/checkpoint',\n",
    "    '--fpv', '10'\n",
    "]\n",
    "args = parse_args(argv)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "daadbcad76cf60b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device: torch.device = args.device\n",
    "source_dir: Path = args.source\n",
    "facedestination_dir: Path = args.facesfolder\n",
    "frames_per_video: int = args.fpv\n",
    "videodataset_path: Path = args.videodf\n",
    "facesdataset_path: Path = args.facesdf\n",
    "collateonly: bool = args.collateonly\n",
    "batch_size: int = args.batch\n",
    "threads: int = args.threads\n",
    "offset: int = args.offset\n",
    "num: int = args.num\n",
    "lazycheck: bool = args.lazycheck\n",
    "deepcheck: bool = args.deepcheck\n",
    "checkpoint_folder: Path = args.checkpoint\n",
    "index_enable: bool = args.noindex\n",
    "\n",
    "## Parameters\n",
    "face_size = 512\n",
    "\n",
    "print('Loading video DataFrame')\n",
    "df_videos = pd.read_pickle(videodataset_path)\n",
    "\n",
    "if num > 0:\n",
    "    df_videos_process = df_videos.iloc[offset:offset + num]\n",
    "else:\n",
    "    df_videos_process = df_videos.iloc[offset:]\n",
    "\n",
    "if not collateonly:\n",
    "\n",
    "    ## Blazeface loading\n",
    "    print('Loading face extractor')\n",
    "    facedet = BlazeFace().to(device)\n",
    "    facedet.load_weights(\"blazeface/blazeface.pth\")\n",
    "    facedet.load_anchors(\"blazeface/anchors.npy\")\n",
    "    videoreader = VideoReader(verbose=False)\n",
    "    video_read_fn = lambda x: videoreader.read_frames(x, num_frames=frames_per_video)\n",
    "    face_extractor = FaceExtractor(video_read_fn, facedet)\n",
    "\n",
    "    ## Face extraction\n",
    "    with ThreadPoolExecutor(threads) as p:\n",
    "        for batch_idx0 in tqdm(np.arange(start=0, stop=len(df_videos_process), step=batch_size),\n",
    "                               desc='Extracting faces'):\n",
    "            tosave_list = list(p.map(partial(process_video,\n",
    "                                             source_dir=source_dir,\n",
    "                                             facedestination_dir=facedestination_dir,\n",
    "                                             checkpoint_folder=checkpoint_folder,\n",
    "                                             face_size=face_size,\n",
    "                                             face_extractor=face_extractor,\n",
    "                                             lazycheck=lazycheck,\n",
    "                                             deepcheck=deepcheck,\n",
    "                                             ),\n",
    "                                     df_videos_process.iloc[batch_idx0:batch_idx0 + batch_size].iterrows()))\n",
    "\n",
    "            for tosave in tosave_list:\n",
    "                if tosave is not None:\n",
    "                    if len(tosave[2]):\n",
    "                        list(p.map(save_jpg, tosave[2]))\n",
    "                    tosave[1].parent.mkdir(parents=True, exist_ok=True)\n",
    "                    tosave[0].to_pickle(str(tosave[1]))\n",
    "\n",
    "if index_enable:\n",
    "    # Collect checkpoints\n",
    "    df_videos['nfaces'] = np.zeros(len(df_videos), np.uint8)\n",
    "    faces_dataset = []\n",
    "    for idx, record in tqdm(df_videos.iterrows(), total=len(df_videos), desc='Collecting faces results'):\n",
    "        # Checkpoint\n",
    "        video_face_checkpoint_path = checkpoint_folder.joinpath(record['path']).with_suffix('.faces.pkl')\n",
    "        if video_face_checkpoint_path.exists():\n",
    "            try:\n",
    "                df_video_faces = pd.read_pickle(str(video_face_checkpoint_path))\n",
    "                # Fix same attribute issue\n",
    "                df_video_faces = df_video_faces.rename(columns={'subject': 'videosubject'}, errors='ignore')\n",
    "                nfaces = len(\n",
    "                    np.unique(df_video_faces.index.map(lambda x: int(x.split('_subj')[1].split('.jpg')[0]))))\n",
    "                df_videos.loc[idx, 'nfaces'] = nfaces\n",
    "                faces_dataset.append(df_video_faces)\n",
    "            except Exception as e:\n",
    "                print('Error while reading: {}'.format(video_face_checkpoint_path))\n",
    "                print(e)\n",
    "                video_face_checkpoint_path.unlink()\n",
    "\n",
    "    if len(faces_dataset) == 0:\n",
    "        raise ValueError(f'No checkpoint found from face extraction. '\n",
    "                         f'Is the the source path {source_dir} correct for the videos in your dataframe?')\n",
    "\n",
    "    # Save videos with updated faces\n",
    "    print('Saving videos DataFrame to {}'.format(videodataset_path))\n",
    "    df_videos.to_pickle(str(videodataset_path))\n",
    "\n",
    "    if offset > 0:\n",
    "        if num > 0:\n",
    "            if facesdataset_path.is_dir():\n",
    "                facesdataset_path = facesdataset_path.joinpath(\n",
    "                    'faces_df_from_video_{}_to_video_{}.pkl'.format(offset, num + offset))\n",
    "            else:\n",
    "                facesdataset_path = facesdataset_path.parent.joinpath(\n",
    "                    str(facesdataset_path.parts[-1]).split('.')[0] + '_from_video_{}_to_video_{}.pkl'.format(offset,\n",
    "                                                                                                             num + offset))\n",
    "        else:\n",
    "            if facesdataset_path.is_dir():\n",
    "                facesdataset_path = facesdataset_path.joinpath('faces_df_from_video_{}.pkl'.format(offset))\n",
    "            else:\n",
    "                facesdataset_path = facesdataset_path.parent.joinpath(\n",
    "                    str(facesdataset_path.parts[-1]).split('.')[0] + '_from_video_{}.pkl'.format(offset))\n",
    "    elif num > 0:\n",
    "        if facesdataset_path.is_dir():\n",
    "            facesdataset_path = facesdataset_path.joinpath(\n",
    "                'faces_df_from_video_{}_to_video_{}.pkl'.format(0, num))\n",
    "        else:\n",
    "            facesdataset_path = facesdataset_path.parent.joinpath(\n",
    "                str(facesdataset_path.parts[-1]).split('.')[0] + '_from_video_{}_to_video_{}.pkl'.format(0, num))\n",
    "    else:\n",
    "        if facesdataset_path.is_dir():\n",
    "            facesdataset_path = facesdataset_path.joinpath('faces_df.pkl')  # just a check if the path is a dir\n",
    "\n",
    "    # Creates directory (if doesn't exist)\n",
    "    facesdataset_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print('Saving faces DataFrame to {}'.format(facesdataset_path))\n",
    "    df_faces = pd.concat(faces_dataset, axis=0, )\n",
    "    df_faces['video'] = df_faces['video'].astype('category')\n",
    "    for key in ['kp1x', 'kp1y', 'kp2x', 'kp2y', 'kp3x',\n",
    "                'kp3y', 'kp4x', 'kp4y', 'kp5x', 'kp5y', 'kp6x', 'kp6y', 'left',\n",
    "                'top', 'right', 'bottom', ]:\n",
    "        df_faces[key] = df_faces[key].astype(np.int16)\n",
    "    df_faces['videosubject'] = df_faces['videosubject'].astype(np.int8)\n",
    "    # Eventually remove duplicates\n",
    "    df_faces = df_faces.loc[~df_faces.index.duplicated(keep='first')]\n",
    "    fields_to_preserve_from_video = [i for i in\n",
    "                                     ['folder', 'subject', 'scene', 'cluster', 'nfaces', 'test'] if\n",
    "                                     i in df_videos]\n",
    "    df_faces = pd.merge(df_faces, df_videos[fields_to_preserve_from_video], left_on='video',\n",
    "                        right_index=True)\n",
    "    df_faces.to_pickle(str(facesdataset_path))\n",
    "\n",
    "print('Completed!')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c660954730c7304"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e238c4762ef26053"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
